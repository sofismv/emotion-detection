{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2540f34a-e618-4103-bcae-b19cc19ab193",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3f2b43ae-bcac-4a4d-9023-814536c336c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import (set_seed, AutoConfig, AutoModelForCausalLM,\n",
        "                          AutoTokenizer, \n",
        "                            BitsAndBytesConfig)\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ef55c712-1638-4065-a5cb-ed5b8073baaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "model_name = \"ISTA-DASLab/Meta-Llama-3-8B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22b45373-2c15-40a9-bce3-f1b6238d1a68",
      "metadata": {},
      "outputs": [],
      "source": [
        "train = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"rus\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5cdfcfb6-eae4-46dc-822d-02ef4e9f6f09",
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_cols = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "emotion_map = {\n",
        "    'anger': 'гнев',\n",
        "    'disgust': 'отвращение', \n",
        "    'fear': 'страх',\n",
        "    'joy': 'радость',\n",
        "    'sadness': 'грусть',\n",
        "    'surprise': 'удивление'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "44b73476-b556-46f5-8ae8-47569094c8e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_labels(examples):\n",
        "    labels = []\n",
        "    for i in range(len(examples['text'])):\n",
        "        label = [examples[col][i] for col in emotion_cols]\n",
        "        labels.append(label)\n",
        "    examples['labels'] = labels\n",
        "    return examples\n",
        "\n",
        "train = train.map(create_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "54065c6e-88fb-4bdc-9d66-101a10d6fbca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Создание эмбеддингов для тренировочных данных...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3e4b271e4364ef2aedf19b459c26cbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/84 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "print(\"Создание эмбеддингов для тренировочных данных...\")\n",
        "train_texts = [row['text'] for row in train]\n",
        "train_embeddings = embedding_model.encode(train_texts, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "361618a9-657f-4f34-ad77-f078bedfd324",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eac2a3c9aac4f24a3f1b13d910c7289",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    use_cache=False,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0b4a0ea0-b06b-42b9-8c5d-54ca20f3475a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a54cad2b-fd03-4158-a698-f52508f2604d",
      "metadata": {},
      "outputs": [],
      "source": [
        "test = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"rus\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c524cdcc-c799-4ce7-8d27-5144b6f9f2f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 42\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2f0f1856-3fe7-4e3c-8ae6-7e2197398c70",
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_examples(query_text, train_data, train_embeddings, k=3):\n",
        "    \"\"\"\n",
        "    Находит k наиболее похожих примеров из трейна для данной эмоции\n",
        "    \"\"\"\n",
        "    query_embedding = embedding_model.encode([query_text])\n",
        "    \n",
        "    similarities = cosine_similarity(query_embedding, train_embeddings)[0]\n",
        "    \n",
        "    similar_indices = np.argsort(similarities)[::-1]\n",
        "    \n",
        "    examples = []\n",
        "    for idx in similar_indices:\n",
        "        if len(examples) >= k:\n",
        "            break\n",
        "        example = train_data[int(idx)]\n",
        "        emotions = []\n",
        "        for col in emotion_cols:\n",
        "            if example[col] == 1:\n",
        "                emotions.append(emotion_map[col])\n",
        "        examples.append((example['text'], emotions))\n",
        "    \n",
        "    return examples[:k]\n",
        "\n",
        "def create_few_shot_prompt(query_text, examples):\n",
        "    \"\"\"\n",
        "    Создает few-shot промпт с примерами\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Ты эксперт по анализу эмоций в тексте. \n",
        "    Определи, какие эмоции выражены в тексте из списка [гнев, отвращение, страх, радость, грусть, удивление.]\n",
        "    Эмоций может быть несколько, а может и вовсе не быть. Формат вывода: только названия эмоций. Если нет эмоций, то оставь пустой список.\n",
        "\n",
        "    ВАЖНЫЕ ПРАВИЛА:\n",
        "    - Ставь 1 ТОЛЬКО если эмоция выражена ЯВНО через конкретные слова, фразы или контекст\n",
        "    - НЕ додумывай скрытые эмоции - только то, что написано прямо\n",
        "    - При сомнениях выбирай 0\n",
        "    \n",
        "    Примеры:\n",
        "    \"\"\"\n",
        "    \n",
        "    # Добавляем примеры\n",
        "    for i, (example_text, emotions) in enumerate(examples, 1):\n",
        "        prompt += f\"Текст: {example_text}\\n\"\n",
        "        prompt += f\"Ответ: {emotions}\\n\\n\"\n",
        "    \n",
        "    # Добавляем целевой текст\n",
        "    prompt += f\"Проанализируй этот текст по тем же критериям:\\n\"\n",
        "    prompt += f\"Текст: {query_text}\\n\"\n",
        "    prompt += f\"Ответ:\"\n",
        "    \n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f907a188-25c6-4b31-9d45-8e76f9cc21e6",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                  | 0/2000 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|███████████████████████████████████████| 2000/2000 [21:50<00:00,  1.53it/s]\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "prompts = []\n",
        "\n",
        "for row in tqdm(test):\n",
        "    labels = []\n",
        "    similar_examples = find_similar_examples(\n",
        "        row['text'], \n",
        "        train, \n",
        "        train_embeddings, \n",
        "        k=2\n",
        "    )\n",
        "    \n",
        "    prompt = create_few_shot_prompt(\n",
        "        row['text'], \n",
        "        similar_examples\n",
        "    )\n",
        "    \n",
        "    prompts.append(prompt)\n",
        "    \n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    \n",
        "    input_ids = tokenizer(formatted_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        temperature=0.1,\n",
        "        do_sample=True,\n",
        "        top_k=1,\n",
        "        top_p=0.9,\n",
        "        max_new_tokens=512,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "    generated_ids = outputs[0][input_ids.shape[1]:]\n",
        "    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "    responses.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dbc12f86-2a2b-48e2-a097-9b04450b928c",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "true_emotions = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c383741a-bbb3-45a4-89a9-384f7126053c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2000it [00:00, 12233.75it/s]\n"
          ]
        }
      ],
      "source": [
        "for i, row in tqdm(enumerate(test)):\n",
        "    true_emotion = [row[col] for col in emotion_cols]\n",
        "    true_emotions.append(true_emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "797ec6dd-bb1f-4baa-b285-a4330fa8b598",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"assistant\\n\\n['отвращение', 'страх']\",\n",
              " 'assistant\\n\\n[радость]',\n",
              " \"assistant\\n\\n['отвращение', 'гнев']\",\n",
              " \"assistant\\n\\n['отвращение', 'гнев']\",\n",
              " \"assistant\\n\\n['радость']\",\n",
              " 'assistant\\n\\n[]',\n",
              " \"assistant\\n\\n['гнев', 'отвращение']\",\n",
              " 'assistant\\n\\n[]',\n",
              " 'assistant\\n\\n[гнев, радость]',\n",
              " \"assistant\\n\\n['страх']\"]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "responses[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d68ce811-bd31-44ee-b13d-9e89ba251b86",
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_values = list(emotion_map.values())\n",
        "\n",
        "def parse_response_to_binary(response: str) -> list[int]:\n",
        "    response = response.lower()\n",
        "    return [1 if emo in response else 0 for emo in emotion_values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c9abb36d-f9e0-41a3-8813-e7b81ea921f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_emotions = [parse_response_to_binary(response) for response in responses]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b2136d68-c67d-4f9c-8864-e464794ecbe8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MICRO recall: 0.7919, precision: 0.4753, f1: 0.5941\n",
            "MACRO recall: 0.7786, precision: 0.5473, f1: 0.6047\n"
          ]
        }
      ],
      "source": [
        "for average in ['micro', 'macro']:\n",
        "    recall = recall_score(true_emotions, pred_emotions, average=average, zero_division=0)\n",
        "    precision = precision_score(true_emotions, pred_emotions, average=average, zero_division=0)\n",
        "    f1 = f1_score(true_emotions, pred_emotions, average=average, zero_division=0)\n",
        "    print(f'{average.upper()} recall: {recall:.4f}, precision: {precision:.4f}, f1: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1c2f6462-ce06-4df0-aa29-27b29a62fa06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "гнев: recall: 0.8894, precision: 0.5560, f1: 0.6843\n",
            "отвращение: recall: 0.9672, precision: 0.2622, f1: 0.4126\n",
            "страх: recall: 0.9167, precision: 0.6851, f1: 0.7842\n",
            "радость: recall: 0.8756, precision: 0.5121, f1: 0.6463\n",
            "грусть: recall: 0.5674, precision: 0.4908, f1: 0.5263\n",
            "удивление: recall: 0.4553, precision: 0.7778, f1: 0.5744\n"
          ]
        }
      ],
      "source": [
        "class_recall = recall_score(true_emotions, pred_emotions, average=None, zero_division=0)\n",
        "class_precision = precision_score(true_emotions, pred_emotions, average=None, zero_division=0)\n",
        "class_f1 = f1_score(true_emotions, pred_emotions, average=None, zero_division=0)\n",
        "\n",
        "for i, (eng_emotion, rus_emotion) in enumerate(emotion_map.items()):\n",
        "    print(f'{rus_emotion}: recall: {class_recall[i]:.4f}, precision: {class_precision[i]:.4f}, f1: {class_f1[i]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fd7782-4d7f-4bcd-8709-3f44ee45cb53",
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_examples(query_text, train_data, train_embeddings, emotion_col, k=4):\n",
        "    \"\"\"\n",
        "    Находит k наиболее похожих примеров из трейна для данной эмоции\n",
        "    \"\"\"\n",
        "    query_embedding = embedding_model.encode([query_text])\n",
        "    \n",
        "    similarities = cosine_similarity(query_embedding, train_embeddings)[0]\n",
        "    \n",
        "    similar_indices = np.argsort(similarities)[::-1]\n",
        "    \n",
        "    positive_examples = []\n",
        "    negative_examples = []\n",
        "    \n",
        "    for idx in similar_indices:\n",
        "        if len(positive_examples) >= k//2 and len(negative_examples) >= k//2:\n",
        "            break\n",
        "            \n",
        "        example = train_data[int(idx)]\n",
        "        \n",
        "        if example[emotion_col] == 1 and len(positive_examples) < k//2:\n",
        "            positive_examples.append((example['text'], 1))\n",
        "        elif example[emotion_col] == 0 and len(negative_examples) < k//2:\n",
        "            negative_examples.append((example['text'], 0))\n",
        "    \n",
        "    all_examples = positive_examples + negative_examples\n",
        "    \n",
        "    return all_examples[:k]\n",
        "\n",
        "def create_few_shot_prompt(query_text, emotion_name, examples):\n",
        "    \"\"\"\n",
        "    Создает few-shot промпт с примерами и строгими критериями\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Ты эксперт по анализу эмоций в тексте. Определи, ЯВНО ли выражена эмоция \"{emotion_name}\" в тексте.\n",
        "\n",
        "ВАЖНЫЕ ПРАВИЛА:\n",
        "- Ставь 1 ТОЛЬКО если эмоция выражена ЯВНО через конкретные слова, фразы или контекст\n",
        "- Ставь 0 если эмоция НЕ выражена явно, даже если можно предположить её наличие\n",
        "- НЕ додумывай скрытые эмоции - только то, что написано прямо\n",
        "- При сомнениях выбирай 0\n",
        "\n",
        "Примеры:\n",
        "\"\"\"\n",
        "    \n",
        "    # Добавляем примеры\n",
        "    for i, (example_text, label) in enumerate(examples, 1):\n",
        "        prompt += f\"Текст: {example_text}\\n\"\n",
        "        prompt += f\"Ответ: {label}\\n\\n\"\n",
        "    \n",
        "    # Добавляем целевой текст\n",
        "    prompt += f\"Проанализируй этот текст по тем же критериям:\\n\"\n",
        "    prompt += f\"Текст: {query_text}\\n\"\n",
        "    prompt += f\"Ответ:\"\n",
        "    \n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324333c6-bb80-4163-9d4e-7fe6ddf12733",
      "metadata": {},
      "outputs": [],
      "source": [
        "responses = []\n",
        "prompts = []\n",
        "\n",
        "for row in tqdm(test):\n",
        "    labels = []\n",
        "    for col in emotion_cols:\n",
        "        similar_examples = find_similar_examples(\n",
        "            row['text'], \n",
        "            col,\n",
        "            train, \n",
        "            train_embeddings, \n",
        "            k=2\n",
        "        )\n",
        "        \n",
        "        prompt = create_few_shot_prompt(\n",
        "            row['text'], \n",
        "            similar_examples\n",
        "        )\n",
        "        \n",
        "        prompts.append(prompt)\n",
        "        \n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "        \n",
        "        input_ids = tokenizer(formatted_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            temperature=0.1,\n",
        "            do_sample=True,\n",
        "            top_k=1,\n",
        "            top_p=0.9,\n",
        "            max_new_tokens=2,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    \n",
        "        generated_text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "        generated_ids = outputs[0][input_ids.shape[1]:]\n",
        "        response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "        labels.append(response)\n",
        "    responses.append(labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.11.7",
      "language": "python",
      "name": "3.11.7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
