{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjnx9IMwaaO_",
    "outputId": "0c3ffbf5-c7a5-4ecf-eb73-334d98b34968"
   },
   "outputs": [],
   "source": [
    "#!pip install -U datasets optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3QdfA7BFZ4Wo"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import set_seed, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import optuna\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wTujAixTZ8GR"
   },
   "outputs": [],
   "source": [
    "train = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"rus\", split=\"train\")\n",
    "# train_eng = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"ukr\", split=\"train\")\n",
    "\n",
    "val = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"rus\", split=\"dev\")\n",
    "# val_eng = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"eng\", split=\"dev\")\n",
    "test = load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"rus\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = concatenate_datasets([train, train_eng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = concatenate_datasets([val, val_eng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_cols = ['anger', 'fear', 'joy', 'disgust', 'sadness', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b178acaf624264871b5da62ef00c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_labels(examples):\n",
    "    labels = []\n",
    "    for i in range(len(examples['text'])):\n",
    "        label = [float(examples[col][i]) for col in emotion_cols]\n",
    "        labels.append(label)\n",
    "    examples['labels'] = labels\n",
    "    return examples\n",
    "\n",
    "train = train.map(create_labels, batched=True)\n",
    "val = val.map(create_labels, batched=True)\n",
    "test = test.map(create_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BFazQwlZaA15"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee47b1533724cb89e9bf28730239056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=False, max_length=512)\n",
    "\n",
    "train_tokenized = train.map(tokenize_function, batched=True)\n",
    "val_tokenized = val.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wKe_qlzHaDOw"
   },
   "outputs": [],
   "source": [
    "train_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rGAetkUKm_R0"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
    "    y_pred = predictions > 0.5\n",
    "\n",
    "    results = {}\n",
    "    for average in ['micro', 'macro']:\n",
    "        results[f'{average}_recall'] = recall_score(labels, y_pred, average=average, zero_division=0)\n",
    "        results[f'{average}_precision'] = precision_score(labels, y_pred, average=average, zero_division=0)\n",
    "        results[f'{average}_f1'] = f1_score(labels, y_pred, average=average, zero_division=0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RYCgEtoOcOMV"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "I-3Xh5vLnFvz"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.3)\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", 0, 500)\n",
    "    num_epochs = trial.suggest_int(\"num_train_epochs\", 2, 7)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(emotion_cols),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/trial_{trial.number}',\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"epoch\",\n",
    "        metric_for_best_model=\"eval_macro_f1\",\n",
    "        logging_dir=f'./logs/trial_{trial.number}',\n",
    "        save_strategy=\"no\",\n",
    "        report_to=None,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=val_tokenized,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    return eval_results[\"eval_macro_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i459Ww7znaYf",
    "outputId": "06563092-44e8-415f-919e-0eb5b7e45b58",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:50:46,047] A new study created in memory with name: no-name-8dc3dd17-b8a6-4239-b0b6-998bec4f3f12\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2345/2345 02:33, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.224113</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.734584</td>\n",
       "      <td>0.720573</td>\n",
       "      <td>0.798664</td>\n",
       "      <td>0.749046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.192610</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.781301</td>\n",
       "      <td>0.807663</td>\n",
       "      <td>0.787782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.194267</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.752696</td>\n",
       "      <td>0.895880</td>\n",
       "      <td>0.809233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.175378</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.866279</td>\n",
       "      <td>0.816438</td>\n",
       "      <td>0.788850</td>\n",
       "      <td>0.877467</td>\n",
       "      <td>0.827310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.770042</td>\n",
       "      <td>0.889119</td>\n",
       "      <td>0.822070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.194129</td>\n",
       "      <td>0.782383</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.827397</td>\n",
       "      <td>0.798349</td>\n",
       "      <td>0.883040</td>\n",
       "      <td>0.834268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.194067</td>\n",
       "      <td>0.782383</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.798349</td>\n",
       "      <td>0.869818</td>\n",
       "      <td>0.828647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:53:21,906] Trial 0 finished with value: 0.8286472173023985 and parameters: {'learning_rate': 4.0880000250683644e-05, 'batch_size': 8, 'weight_decay': 0.1896718711665509, 'warmup_steps': 94, 'num_train_epochs': 7}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 00:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.384289</td>\n",
       "      <td>0.202073</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.274962</td>\n",
       "      <td>0.207540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.292123</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.427599</td>\n",
       "      <td>0.756774</td>\n",
       "      <td>0.533381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:53:52,202] Trial 1 finished with value: 0.5333814333814334 and parameters: {'learning_rate': 1.097708908459796e-05, 'batch_size': 16, 'weight_decay': 0.02690975343175591, 'warmup_steps': 260, 'num_train_epochs': 2}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 01:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.257719</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>0.848238</td>\n",
       "      <td>0.671770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.208931</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.739293</td>\n",
       "      <td>0.882121</td>\n",
       "      <td>0.793057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.184106</td>\n",
       "      <td>0.704663</td>\n",
       "      <td>0.877419</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.721193</td>\n",
       "      <td>0.890516</td>\n",
       "      <td>0.788572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:54:59,200] Trial 2 finished with value: 0.7885720072716738 and parameters: {'learning_rate': 4.837599564129313e-05, 'batch_size': 8, 'weight_decay': 0.1478881164993717, 'warmup_steps': 465, 'num_train_epochs': 3}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2010' max='2010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2010/2010 02:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.439399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.438878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.442411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.438270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>0.438905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:57:10,533] Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 0.00020096667289333227, 'batch_size': 8, 'weight_decay': 0.08350964310886518, 'warmup_steps': 197, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2010' max='2010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2010/2010 02:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.441182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.440606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>0.442471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.438971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.438445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.429800</td>\n",
       "      <td>0.439886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 22:59:23,565] Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 0.00020769807822696386, 'batch_size': 8, 'weight_decay': 0.27862641151560985, 'warmup_steps': 193, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2345/2345 02:32, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.318311</td>\n",
       "      <td>0.331606</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.458781</td>\n",
       "      <td>0.350122</td>\n",
       "      <td>0.372312</td>\n",
       "      <td>0.358608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.351824</td>\n",
       "      <td>0.279793</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.321590</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.343062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.574798</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.600279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.664723</td>\n",
       "      <td>0.581559</td>\n",
       "      <td>0.666206</td>\n",
       "      <td>0.619110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>0.621762</td>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.662983</td>\n",
       "      <td>0.611599</td>\n",
       "      <td>0.646681</td>\n",
       "      <td>0.623912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.256199</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.708215</td>\n",
       "      <td>0.637769</td>\n",
       "      <td>0.687343</td>\n",
       "      <td>0.658568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.257150</td>\n",
       "      <td>0.632124</td>\n",
       "      <td>0.767296</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.625775</td>\n",
       "      <td>0.680613</td>\n",
       "      <td>0.648272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:01:58,047] Trial 5 finished with value: 0.6482715659537543 and parameters: {'learning_rate': 0.00013954209946765182, 'batch_size': 8, 'weight_decay': 0.1484940977614722, 'warmup_steps': 250, 'num_train_epochs': 7}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541400</td>\n",
       "      <td>0.350888</td>\n",
       "      <td>0.233161</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>0.202363</td>\n",
       "      <td>0.247868</td>\n",
       "      <td>0.222751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.201046</td>\n",
       "      <td>0.699482</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.901413</td>\n",
       "      <td>0.795182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.185641</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.732702</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.807528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.219860</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.759644</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>0.909352</td>\n",
       "      <td>0.753056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.199624</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.803324</td>\n",
       "      <td>0.763209</td>\n",
       "      <td>0.864637</td>\n",
       "      <td>0.807713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:03:00,200] Trial 6 finished with value: 0.8077129643832414 and parameters: {'learning_rate': 0.00011404349552787183, 'batch_size': 32, 'weight_decay': 0.23353708835005116, 'warmup_steps': 344, 'num_train_epochs': 5}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2010' max='2010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2010/2010 02:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.248663</td>\n",
       "      <td>0.595855</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.662824</td>\n",
       "      <td>0.615578</td>\n",
       "      <td>0.758761</td>\n",
       "      <td>0.675893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.221408</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.749455</td>\n",
       "      <td>0.816191</td>\n",
       "      <td>0.778443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.815864</td>\n",
       "      <td>0.755820</td>\n",
       "      <td>0.915235</td>\n",
       "      <td>0.825667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.898081</td>\n",
       "      <td>0.815112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.193448</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.760291</td>\n",
       "      <td>0.907979</td>\n",
       "      <td>0.823274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.186879</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.871345</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.777968</td>\n",
       "      <td>0.882786</td>\n",
       "      <td>0.823307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:05:14,126] Trial 7 finished with value: 0.8233069577941862 and parameters: {'learning_rate': 6.861230099609194e-05, 'batch_size': 8, 'weight_decay': 0.03700627649030581, 'warmup_steps': 73, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2345/2345 02:32, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.598687</td>\n",
       "      <td>0.191710</td>\n",
       "      <td>0.229814</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.248474</td>\n",
       "      <td>0.214527</td>\n",
       "      <td>0.157259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.440779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.441157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.438315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.437057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>0.437090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.437974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:07:47,740] Trial 8 finished with value: 0.0 and parameters: {'learning_rate': 0.0002059288170791529, 'batch_size': 8, 'weight_decay': 0.1022161063626476, 'warmup_steps': 417, 'num_train_epochs': 7}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1176' max='1176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1176/1176 01:40, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.409326</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.452072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.436703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.446019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.441123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.439794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>0.437522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:09:29,783] Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 0.00047947502621289377, 'batch_size': 16, 'weight_decay': 0.19436212778263576, 'warmup_steps': 357, 'num_train_epochs': 7}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 00:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.316791</td>\n",
       "      <td>0.352332</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.366624</td>\n",
       "      <td>0.631112</td>\n",
       "      <td>0.442442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.668394</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.752187</td>\n",
       "      <td>0.689188</td>\n",
       "      <td>0.871307</td>\n",
       "      <td>0.762448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.183538</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.808023</td>\n",
       "      <td>0.739705</td>\n",
       "      <td>0.917386</td>\n",
       "      <td>0.814989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.143400</td>\n",
       "      <td>0.178058</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>0.752373</td>\n",
       "      <td>0.897091</td>\n",
       "      <td>0.815579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:10:19,554] Trial 10 finished with value: 0.8155792620078334 and parameters: {'learning_rate': 2.8118082064076645e-05, 'batch_size': 32, 'weight_decay': 0.2108715764777704, 'warmup_steps': 16, 'num_train_epochs': 4}. Best is trial 0 with value: 0.8286472173023985.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1675' max='1675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1675/1675 01:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.250155</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.778007</td>\n",
       "      <td>0.722978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.193995</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.795580</td>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.758829</td>\n",
       "      <td>0.811112</td>\n",
       "      <td>0.779469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.166914</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>0.783552</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.833799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.169130</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>0.783023</td>\n",
       "      <td>0.872561</td>\n",
       "      <td>0.824112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.178134</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.829132</td>\n",
       "      <td>0.775931</td>\n",
       "      <td>0.899690</td>\n",
       "      <td>0.830439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:12:11,881] Trial 11 finished with value: 0.8304391511179802 and parameters: {'learning_rate': 3.6080447584106924e-05, 'batch_size': 8, 'weight_decay': 0.01575328599390322, 'warmup_steps': 33, 'num_train_epochs': 5}. Best is trial 11 with value: 0.8304391511179802.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 01:26, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.227168</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.680764</td>\n",
       "      <td>0.883433</td>\n",
       "      <td>0.746411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.178116</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.767905</td>\n",
       "      <td>0.872580</td>\n",
       "      <td>0.812162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.166217</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.828169</td>\n",
       "      <td>0.769574</td>\n",
       "      <td>0.912677</td>\n",
       "      <td>0.832382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.162058</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.896970</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.776559</td>\n",
       "      <td>0.902448</td>\n",
       "      <td>0.832499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:13:39,811] Trial 12 finished with value: 0.8324990546825356 and parameters: {'learning_rate': 2.868318448990469e-05, 'batch_size': 8, 'weight_decay': 0.004901939692684662, 'warmup_steps': 87, 'num_train_epochs': 4}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 01:26, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.258236</td>\n",
       "      <td>0.616580</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>0.697947</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.802675</td>\n",
       "      <td>0.673322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.184504</td>\n",
       "      <td>0.715026</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.795389</td>\n",
       "      <td>0.734067</td>\n",
       "      <td>0.891982</td>\n",
       "      <td>0.802361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.176652</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.761019</td>\n",
       "      <td>0.876137</td>\n",
       "      <td>0.812172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.178653</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.892405</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.748872</td>\n",
       "      <td>0.899714</td>\n",
       "      <td>0.812444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:15:07,688] Trial 13 finished with value: 0.8124441130074933 and parameters: {'learning_rate': 1.9099410076449836e-05, 'batch_size': 8, 'weight_decay': 0.013061325859571286, 'warmup_steps': 18, 'num_train_epochs': 4}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.600300</td>\n",
       "      <td>0.386904</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.260090</td>\n",
       "      <td>0.123932</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.140097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.255036</td>\n",
       "      <td>0.569948</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.565678</td>\n",
       "      <td>0.862515</td>\n",
       "      <td>0.665780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.208959</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.762463</td>\n",
       "      <td>0.690444</td>\n",
       "      <td>0.895207</td>\n",
       "      <td>0.765360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.182298</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.761027</td>\n",
       "      <td>0.880656</td>\n",
       "      <td>0.813876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.175694</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.754411</td>\n",
       "      <td>0.871324</td>\n",
       "      <td>0.807315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:16:09,459] Trial 14 finished with value: 0.807314511019552 and parameters: {'learning_rate': 2.0782918150713653e-05, 'batch_size': 32, 'weight_decay': 0.07459355483959683, 'warmup_steps': 119, 'num_train_epochs': 5}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [504/504 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.350460</td>\n",
       "      <td>0.233161</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.259517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.266206</td>\n",
       "      <td>0.523316</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.515240</td>\n",
       "      <td>0.687037</td>\n",
       "      <td>0.576435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.244682</td>\n",
       "      <td>0.569948</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.681115</td>\n",
       "      <td>0.578813</td>\n",
       "      <td>0.859662</td>\n",
       "      <td>0.665903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:16:54,056] Trial 15 finished with value: 0.6659028165720425 and parameters: {'learning_rate': 1.1679984563154842e-05, 'batch_size': 16, 'weight_decay': 0.05590774502094219, 'warmup_steps': 144, 'num_train_epochs': 3}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 01:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.216022</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.732872</td>\n",
       "      <td>0.843691</td>\n",
       "      <td>0.774051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.191692</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.789120</td>\n",
       "      <td>0.853830</td>\n",
       "      <td>0.813855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.162737</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.760821</td>\n",
       "      <td>0.900599</td>\n",
       "      <td>0.820389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.157060</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>0.785007</td>\n",
       "      <td>0.893450</td>\n",
       "      <td>0.830656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:18:23,645] Trial 16 finished with value: 0.8306558552978859 and parameters: {'learning_rate': 3.669527734640834e-05, 'batch_size': 8, 'weight_decay': 0.006464328297945909, 'warmup_steps': 48, 'num_train_epochs': 4}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 01:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.701647</td>\n",
       "      <td>0.789679</td>\n",
       "      <td>0.713287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.188981</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.856287</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.757374</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.799377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.173772</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.763784</td>\n",
       "      <td>0.868298</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:19:31,090] Trial 17 finished with value: 0.8095885474800011 and parameters: {'learning_rate': 6.831230146811595e-05, 'batch_size': 8, 'weight_decay': 0.11994908355548693, 'warmup_steps': 175, 'num_train_epochs': 3}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [672/672 00:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.307444</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.262101</td>\n",
       "      <td>0.568793</td>\n",
       "      <td>0.329893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.217714</td>\n",
       "      <td>0.658031</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.762763</td>\n",
       "      <td>0.669283</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.761017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.182761</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.809117</td>\n",
       "      <td>0.748827</td>\n",
       "      <td>0.900708</td>\n",
       "      <td>0.815086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.178386</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>0.744508</td>\n",
       "      <td>0.890126</td>\n",
       "      <td>0.808349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:20:29,766] Trial 18 finished with value: 0.8083493272696304 and parameters: {'learning_rate': 1.945216770154496e-05, 'batch_size': 16, 'weight_decay': 0.0032558539641831833, 'warmup_steps': 62, 'num_train_epochs': 4}. Best is trial 12 with value: 0.8324990546825356.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638500</td>\n",
       "      <td>0.410631</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.312186</td>\n",
       "      <td>0.383420</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.370661</td>\n",
       "      <td>0.719124</td>\n",
       "      <td>0.474571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 23:20:55,365] Trial 19 finished with value: 0.474571137370383 and parameters: {'learning_rate': 2.8803463262445056e-05, 'batch_size': 32, 'weight_decay': 0.05853958492161683, 'warmup_steps': 286, 'num_train_epochs': 2}. Best is trial 12 with value: 0.8324990546825356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters:\n",
      "{'learning_rate': 2.868318448990469e-05, 'batch_size': 8, 'weight_decay': 0.004901939692684662, 'warmup_steps': 87, 'num_train_epochs': 4}\n",
      "Best macro F1: 0.8325\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(study.best_params)\n",
    "print(f\"Best macro F1: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4240920430.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mBest hyperparameters:\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Best hyperparameters:\n",
    "{'learning_rate': 1.952733015072204e-05, 'batch_size': 16, 'weight_decay': 0.28658541378102453, 'warmup_steps': 471, 'num_train_epochs': 7}\n",
    "Best macro F1: 0.9054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KpwnBA4pngFA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 01:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.234877</td>\n",
       "      <td>0.637306</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.715116</td>\n",
       "      <td>0.636522</td>\n",
       "      <td>0.823705</td>\n",
       "      <td>0.704607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.775043</td>\n",
       "      <td>0.833577</td>\n",
       "      <td>0.798757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.164405</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.765201</td>\n",
       "      <td>0.920944</td>\n",
       "      <td>0.831661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.160479</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.831025</td>\n",
       "      <td>0.780635</td>\n",
       "      <td>0.899369</td>\n",
       "      <td>0.833552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1340, training_loss=0.1875365776802177, metrics={'train_runtime': 87.6756, 'train_samples_per_second': 122.223, 'train_steps_per_second': 15.284, 'total_flos': 248538900917736.0, 'train_loss': 0.1875365776802177, 'epoch': 4.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(emotion_cols),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./best_model',\n",
    "    num_train_epochs=best_params[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=best_params[\"batch_size\"],\n",
    "    per_device_eval_batch_size=best_params[\"batch_size\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    weight_decay=best_params[\"weight_decay\"],\n",
    "    warmup_steps=best_params[\"warmup_steps\"],\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir='./logs/best_model',\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "--Q_HdIVaN3y"
   },
   "outputs": [],
   "source": [
    "def find_best_threshold(model, val_dataset, thresholds=np.arange(0.1, 0.9, 0.05)):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    probs = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    optimal_thresholds = {}\n",
    "    best_f1_scores = {}\n",
    "    \n",
    "    print(\"Finding optimal thresholds for each emotion:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Find optimal threshold for each emotion separately\n",
    "    for i, emotion in enumerate(emotion_cols):\n",
    "        best_threshold = 0.5\n",
    "        best_f1 = 0\n",
    "        \n",
    "        print(f\"\\n{emotion.upper()}:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            # Binary predictions for this emotion only\n",
    "            y_pred_emotion = (probs[:, i] > threshold).astype(int)\n",
    "            y_true_emotion = true_labels[:, i]\n",
    "            \n",
    "            # Calculate F1 for this emotion\n",
    "            f1_emotion = f1_score(y_true_emotion, y_pred_emotion, zero_division=0)\n",
    "            \n",
    "            print(f\"Threshold {threshold:.2f}: F1 = {f1_emotion:.4f}\")\n",
    "            \n",
    "            if f1_emotion > best_f1:\n",
    "                best_f1 = f1_emotion\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        optimal_thresholds[emotion] = best_threshold\n",
    "        best_f1_scores[emotion] = best_f1\n",
    "        \n",
    "        print(f\"Best threshold for {emotion}: {best_threshold:.2f} (F1: {best_f1:.4f})\")\n",
    "    return optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(model, val_dataset, thresholds=np.arange(0.1, 0.9, 0.05)):\n",
    "    model.eval()\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    probs = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
    "    true_labels = predictions.label_ids\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    print(\"Threshold optimization:\")\n",
    "    for threshold in thresholds:\n",
    "        y_pred = probs > threshold\n",
    "        f1_macro = f1_score(true_labels, y_pred, average='macro', zero_division=0)\n",
    "        print(f\"Threshold {threshold:.2f}: Macro F1 = {f1_macro:.4f}\")\n",
    "        if f1_macro > best_f1:\n",
    "            best_f1 = f1_macro\n",
    "            best_threshold = threshold\n",
    "    print(f\"\\nBest threshold: {best_threshold:.2f} (Macro F1: {best_f1:.4f})\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "4y6fDOtJaPUn",
    "outputId": "5900e4e0-b1a6-45e0-bae6-146f23d28583"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold optimization:\n",
      "Threshold 0.10: Macro F1 = 0.7770\n",
      "Threshold 0.15: Macro F1 = 0.8143\n",
      "Threshold 0.20: Macro F1 = 0.8246\n",
      "Threshold 0.25: Macro F1 = 0.8375\n",
      "Threshold 0.30: Macro F1 = 0.8383\n",
      "Threshold 0.35: Macro F1 = 0.8480\n",
      "Threshold 0.40: Macro F1 = 0.8481\n",
      "Threshold 0.45: Macro F1 = 0.8437\n",
      "Threshold 0.50: Macro F1 = 0.8336\n",
      "Threshold 0.55: Macro F1 = 0.8290\n",
      "Threshold 0.60: Macro F1 = 0.8329\n",
      "Threshold 0.65: Macro F1 = 0.8325\n",
      "Threshold 0.70: Macro F1 = 0.8344\n",
      "Threshold 0.75: Macro F1 = 0.8222\n",
      "Threshold 0.80: Macro F1 = 0.8157\n",
      "Threshold 0.85: Macro F1 = 0.7954\n",
      "\n",
      "Best threshold: 0.40 (Macro F1: 0.8481)\n"
     ]
    }
   ],
   "source": [
    "best_threshold = find_best_threshold(model, val_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9fb30d0f79344f31b94aeee44a9d6f80",
      "1cc55b7bbe1343d59d3d4e8954ec9160",
      "dfc19e9af08c4afbb73dbc78b946d534",
      "3d9f092a4f964b2db730b6133ea655af",
      "1be3ef91765a47139fb65d12333456e6",
      "44fc950f24854d229cac262d8d58ac74",
      "b97c8c446c5147548a652db53b436fb7",
      "1369672c7b9148b6854193f03ecfd263",
      "89d1efbf37ae437f8bd1c694b7e1c926",
      "1a2ee13e358f4ae6a19a573dea7f2a2b",
      "3fad48d7fea24f15a614bda263557536"
     ]
    },
    "id": "DkC_7CvSaP0k",
    "outputId": "8ef2ee5e-11d2-4454-b15d-7ea3554d08c6"
   },
   "outputs": [],
   "source": [
    "# test_tokenized = test.map(tokenize_function, batched=True)\n",
    "# test_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# test_predictions = trainer.predict(test_tokenized)\n",
    "# test_probs = torch.sigmoid(torch.tensor(test_predictions.predictions)).numpy()\n",
    "# test_pred_labels = test_probs > best_threshold\n",
    "# true_test_labels = test_predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1875082c264a749ce326c153c2fc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokenized = test.map(tokenize_function, batched=True)\n",
    "test_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "test_predictions = trainer.predict(test_tokenized)\n",
    "test_probs = torch.sigmoid(torch.tensor(test_predictions.predictions)).numpy()\n",
    "test_pred_labels = np.zeros_like(test_probs)\n",
    "for i, emotion in enumerate(emotion_cols):\n",
    "    test_pred_labels[:, i] = (test_probs[:, i] > 0.5).astype(int)\n",
    "true_test_labels = test_predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l5MntZBaRou",
    "outputId": "e4c124e9-e337-4484-84ba-b982d6f60516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO recall: 0.7777, precision: 0.8712, f1: 0.8218\n",
      "MACRO recall: 0.7782, precision: 0.8762, f1: 0.8225\n",
      "\n",
      "Per-class Results:\n",
      "ANGER: recall: 0.7611, precision: 0.839, f1: 0.7981\n",
      "FEAR: recall: 0.8611, precision: 0.8774, f1: 0.8692\n",
      "JOY: recall: 0.8238, precision: 0.8933, f1: 0.8571\n",
      "DISGUST: recall: 0.7049, precision: 0.9451, f1: 0.8075\n",
      "SADNESS: recall: 0.7376, precision: 0.8889, f1: 0.8062\n",
      "SURPRISE: recall: 0.7805, precision: 0.8136, f1: 0.7967\n",
      "\n",
      "Class distribution in test set:\n",
      "ANGER: true: 452/2000 (22.6%), predicted: 410/2000 (20.5%)\n",
      "FEAR: true: 216/2000 (10.8%), predicted: 212/2000 (10.6%)\n",
      "JOY: true: 386/2000 (19.3%), predicted: 356/2000 (17.8%)\n",
      "DISGUST: true: 244/2000 (12.2%), predicted: 182/2000 (9.1%)\n",
      "SADNESS: true: 282/2000 (14.1%), predicted: 234/2000 (11.7%)\n",
      "SURPRISE: true: 246/2000 (12.3%), predicted: 236/2000 (11.8%)\n"
     ]
    }
   ],
   "source": [
    "# print(f\"\\nTest Results with optimal threshold ({best_threshold:.2f}):\")\n",
    "for average in ['micro', 'macro']:\n",
    "    recall = recall_score(true_test_labels, test_pred_labels, average=average, zero_division=0)\n",
    "    precision = precision_score(true_test_labels, test_pred_labels, average=average, zero_division=0)\n",
    "    f1 = f1_score(true_test_labels, test_pred_labels, average=average, zero_division=0)\n",
    "    print(f'{average.upper()} recall: {round(recall, 4)}, precision: {round(precision, 4)}, f1: {round(f1, 4)}')\n",
    "\n",
    "print(f\"\\nPer-class Results:\")\n",
    "class_recall = recall_score(true_test_labels, test_pred_labels, average=None, zero_division=0)\n",
    "class_precision = precision_score(true_test_labels, test_pred_labels, average=None, zero_division=0)\n",
    "class_f1 = f1_score(true_test_labels, test_pred_labels, average=None, zero_division=0)\n",
    "\n",
    "for i, emotion in enumerate(emotion_cols):\n",
    "    print(f'{emotion.upper()}: recall: {round(class_recall[i], 4)}, precision: {round(class_precision[i], 4)}, f1: {round(class_f1[i], 4)}')\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "for i, emotion in enumerate(emotion_cols):\n",
    "    true_count = int(true_test_labels[:, i].sum())\n",
    "    pred_count = int(test_pred_labels[:, i].sum())\n",
    "    total = len(true_test_labels)\n",
    "    print(f'{emotion.upper()}: true: {true_count}/{total} ({true_count/total:.1%}), predicted: {pred_count}/{total} ({pred_count/total:.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bert.npy', test_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01563433, 0.9697105 , 0.01789523, 0.0131724 , 0.01356052,\n",
       "        0.01505389],\n",
       "       [0.00515464, 0.00593253, 0.00646108, 0.00496511, 0.00630429,\n",
       "        0.00407498],\n",
       "       [0.98380107, 0.01522074, 0.01516229, 0.02613696, 0.02344373,\n",
       "        0.01456004],\n",
       "       ...,\n",
       "       [0.09306297, 0.00388846, 0.00349513, 0.00452616, 0.03717936,\n",
       "        0.00292134],\n",
       "       [0.0076504 , 0.02186554, 0.02283526, 0.01351371, 0.01696276,\n",
       "        0.96584934],\n",
       "       [0.00909997, 0.01079418, 0.98410505, 0.00929993, 0.0122868 ,\n",
       "        0.00937763]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "3.11.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1369672c7b9148b6854193f03ecfd263": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a2ee13e358f4ae6a19a573dea7f2a2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1be3ef91765a47139fb65d12333456e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cc55b7bbe1343d59d3d4e8954ec9160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44fc950f24854d229cac262d8d58ac74",
      "placeholder": "​",
      "style": "IPY_MODEL_b97c8c446c5147548a652db53b436fb7",
      "value": "Map: 100%"
     }
    },
    "3d9f092a4f964b2db730b6133ea655af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a2ee13e358f4ae6a19a573dea7f2a2b",
      "placeholder": "​",
      "style": "IPY_MODEL_3fad48d7fea24f15a614bda263557536",
      "value": " 2000/2000 [00:00&lt;00:00, 7377.18 examples/s]"
     }
    },
    "3fad48d7fea24f15a614bda263557536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44fc950f24854d229cac262d8d58ac74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89d1efbf37ae437f8bd1c694b7e1c926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fb30d0f79344f31b94aeee44a9d6f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1cc55b7bbe1343d59d3d4e8954ec9160",
       "IPY_MODEL_dfc19e9af08c4afbb73dbc78b946d534",
       "IPY_MODEL_3d9f092a4f964b2db730b6133ea655af"
      ],
      "layout": "IPY_MODEL_1be3ef91765a47139fb65d12333456e6"
     }
    },
    "b97c8c446c5147548a652db53b436fb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfc19e9af08c4afbb73dbc78b946d534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1369672c7b9148b6854193f03ecfd263",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89d1efbf37ae437f8bd1c694b7e1c926",
      "value": 2000
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
